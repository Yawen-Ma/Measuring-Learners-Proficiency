# This is the R script contains the data cleaning and the model application (model application starts from row 383)
####################################### Package loading #######################################
pkgs <- c('dplyr', 'tidyverse', # data cleaning and data pre-processing, be used to create the engagement data
          'ggplot2', # powerful data visualization 
          'mclust', # apply the Gaussian graphical models, and examine the BIC (Bayesian Information Criterion) results generated by models
          'factoextra', # apply the clustering algorithms, including k-means, k-medoids, clustering large applications, hierarchical clustering, as well as visualization and silhouette coefficients of the clustering results
          'fpc', # perform clustering validation metrics including Dunn index and within cluster sum of squares
          'extrafont', # into a uniform font e.g. Times New Roman, 12pt, Bold
          'readr', # read the dataset
          'fmsb',
          'lme4'
)
ins <- lapply(pkgs, library, character.only = T) #character.only is for accepting the character of "pkgs"
# read csv of your datasets
user_engagement1 <- read_csv("/Users/yawenma/Downloads/Rstudio_my_code/Amplify_games_test/2024new_dataset/2024_newdataset/REDOPLUS_user_engagement4skills_withknlabel_MAY.csv") # the generated dataset including clustering label for each user and indicators of engagement
subskills_clean <- read_csv("/Users/yawenma/Downloads/Rstudio_my_code/Amplify_games_test/2024new_dataset/2024_newdataset/subskills_clean_May.csv") # log file
subskills_clean <- subskills_clean %>% mutate(game_id = case_when(game_id == "storyboard" ~ "sb_storyboard",TRUE ~ game_id))
# Change cluster == 8 to cluster == 1 in subskills_clean
user_engagement1_relabel <- user_engagement1 %>%
  mutate(cluster = case_when(cluster == 8 ~ 1,
  cluster == 1 ~ 2,
  cluster == 2 ~ 3,
    cluster == 3 ~ 4,
    cluster == 4 ~ 5,
    cluster == 5 ~ 6,
    cluster == 6 ~ 7,
    cluster == 7 ~ 8,
    cluster == 9 ~ 9))
user_engagement1_relabel %>% group_by(cluster) %>% summarise(n = n_distinct(user_id))
clusters <- list()
for (i in 1:9) {
    a <- user_engagement1_relabel %>% dplyr::select(user_id, cluster)
    clusters[[i]] <- left_join(subskills_clean, a, by = "user_id") %>% filter(cluster == i)
}
####################################### Data cleaning #######################################
# Load the logfile data and the data contained clusters label with engagement information
# when you have the time, copy the old code for tables of clusters information about engagement
# clean data including
## 1. for each cluster, add the grade G1 G2 variable
## 2. check mastery, create the true mastery variable for each game
## 3. leave with the first mastery and no measurements after mastering the level
## 4. select the levels based on porportion >= 1% 
## 5. check the number of attempts, 7 for three games, 3 for one game (MC - storyboard)
## 6. check the number of levels, ignore for three games, 3 for one game (ED - curioso crossing)
## 6update. check the number of levels, for PA ED V selected those who played >= 3 level, ignore MC since only 5 levels in total
## 7. find both grades common users
###### You only use this in GMM ## even no need, since remove missing and automatically give the final users, but since find both PA_ED/ V_MC common users give too less to run SIRT model, ignore this one #################
## 9. change check_mastery from TRUE/FALSE to 1/0
###### following 7 steps, here is the way of cleaning data
# Loop over each cluster
for (i in 1:length(clusters)) {
  # Loop over each game
    # 1. Add the grade G1 G2 variable
    clusters[[i]] <- clusters[[i]] %>%
      mutate(
        round_started_at_date = as.Date(round_started_at),
        grade = ifelse(round_started_at_date >= as.Date("2021-07-18") & round_started_at_date < as.Date("2022-07-18"), 1, 2)) # replace condition with your condition
  }
  # Create an empty list to store the data frames
df_list <- list()
# Loop over each cluster
for (i in 1:9) {
  # Filter the data for each grade and store in the list
  df_list[[paste0("C", i, "_G1")]] <- clusters[[i]] %>% filter(grade == 1)
  df_list[[paste0("C", i, "_G2")]] <- clusters[[i]] %>% filter(grade == 2)
}

# Now you can access the data frames with df_list[["C1_G1"]], df_list[["C9_G2"]], etc.
    # 2. Check mastery, create the true mastery variable for each game
    process_game_data <- function(game_data, game_name, is_level_mastered) {
        check_mastery <- NULL
  if (game_name == "all_aboard") {
    game_data <- game_data %>%
      mutate(total_questions = case_when(
        game_level >= 1 & game_level <= 3 ~ 6,
        game_level >= 4 & game_level <= 12 ~ 8,
        game_level >= 13 & game_level <= 15 ~ 6,
        game_level >= 16 & game_level <= 24 ~ 8),
        error_questions = total_questions - fact_reading_round.questions_correct)
    
    check_mastery <- function(game_level, error_questions, is_level_mastered) {
      if (game_level >= 1 && game_level <= 24) {
        return(error_questions <= 1)
      } 
      return(FALSE)
    }
  } else if (game_name == "curioso_crossing") {
    game_data <- game_data %>%
      mutate(total_questions = case_when(
        game_level >= 1 & game_level <= 4 ~ 6,
        game_level >= 5 & game_level <= 6 ~ 8,
        game_level >= 7 & game_level <= 70 ~ 15),
        error_questions = total_questions - fact_reading_round.questions_correct)
    
    check_mastery <- function(game_level, error_questions, is_level_mastered) {
      if (game_level >= 1 && game_level <= 6) {
        return(error_questions <= 1)
      } else if (game_level >= 7 && game_level <= 70) {
        return(error_questions <= 2)
      }
      return(FALSE)
    }
  } else if (game_name == "sticker_book") {
    game_data <- game_data %>%
      mutate(total_questions = 9,
             error_questions = total_questions - fact_reading_round.questions_correct)
    
    check_mastery <- function(game_level, error_questions, is_level_mastered) {
      if (game_level >= 1 && game_level <= 5) {
        return(is_level_mastered)
      }
      if (game_level >= 6 && game_level <= 17) {
        return(error_questions <= 3)
      } 
      return(FALSE)
    }
  } else if (game_name == "sb_storyboard") {
    game_data <- game_data %>% 
      mutate(total_questions = 8,
             error_questions = total_questions - fact_reading_round.questions_correct)
    
    check_mastery <- function(game_level, error_questions, is_level_mastered) {
      if (game_level >= 1 && game_level <= 5) {
        return(error_questions <= 2)
      } 
      return(FALSE)
    }
  }
   if (!is.null(check_mastery)) {
    game_data$check_mastery <- mapply(check_mastery, game_data$game_level, game_data$error_questions, game_data$is_level_mastered)
  }
  return(game_data)
}

# Define the games
games <- c("all_aboard", "curioso_crossing", "sticker_book", "sb_storyboard")
# Create an empty list to store the processed data frames
processed_data <- list()
# Loop over each cluster and grade
for (i in 1:9) {
  for (j in 1:2) {
    # Get the data frame for this cluster and grade
    df <- df_list[[paste0("C", i, "_G", j)]]
    # Extract is_level_mastered
    is_level_mastered <- df$is_level_mastered
    # Loop over each game
    for (game in games) {
      # Process the data and store in the list
      processed_data[[paste0("C", i, "_G", j, "_", substr(game, 1, 2))]] <- process_game_data(df, game, is_level_mastered)
    }
  }
}
# Now you can access the processed data frames with processed_data[["C1_G1_al"]], processed_data[["C1_G1_cu"]], processed_data[["C1_G1_st"]], processed_data[["C1_G1_sb"]], etc.

###### Add step, you want to filter the game, so that processed_data only contains the data for the game you are interested in
filter_game <- function(data, name) {
    if (grepl("_al", name)) {
        return(dplyr::filter(data, game_id == "all_aboard"))
    } else if (grepl("_cu", name)) {
        return(dplyr::filter(data, game_id == "curioso_crossing"))
    } else if (grepl("_st", name)) {
        return(dplyr::filter(data, game_id == "sticker_book"))
    } else if (grepl("_sb", name)) {
        return(dplyr::filter(data, game_id == "sb_storyboard"))
    } else {
        return(NULL)
    }
}
# Apply the function to each dataset in the list
processed_data1 <- mapply(filter_game, processed_data, names(processed_data), SIMPLIFY = FALSE)

    # 3. Leave with the first mastery and no measurements after mastering the level
    # Define the keys for the data frames you want to process
clusters <- c("C1", "C2", "C3", "C4", "C5", "C6", "C7", "C8", "C9")
games <- c("al", "cu", "st", "sb")
keys <- c()
for (cluster in clusters) {
  for (game in games) {
    keys <- c(keys, paste0(cluster, "_G1_", game))
  }
}
# Loop over each key
for (key in keys) {
  # Apply the operations to the data frame
  processed_data1[[key]] <- processed_data1[[key]] %>%
    filter(!is.na(round_completed_at)) %>%
    filter(!is.na(elapsed_time_m)) %>%
    filter(is_early_exit == FALSE) %>%
    filter(!is.na(is_level_mastered)) %>%
    filter(!is.na(check_mastery)) %>%
    group_by(user_id, game_id, game_level) %>%
    arrange(user_id, game_id, game_level, round_started_at) %>%
    distinct(user_id, game_id, game_level, round_started_at, check_mastery, fact_reading_round.proportion_correct, .keep_all = TRUE) %>%
    group_by(user_id, game_id, game_level) %>%
    filter(!duplicated(check_mastery) | check_mastery == FALSE) %>%
    group_by(user_id, game_id, game_level) %>%
    mutate(nth_attempt = 1:length(game_level),
           min_true_attempt = ifelse(any(check_mastery == 1), 
                                     min(nth_attempt[check_mastery == 1]), 
                                     Inf)) %>%
    filter(nth_attempt <= min_true_attempt) %>%
    ungroup() %>%
    select(-min_true_attempt)
}
    # 4. Select the levels based on proportion >= 1%
    process_data <- function(df){
    a <- df %>%
    group_by(game_level) %>%
    summarise(unique_students = n_distinct(user_id),
              total_students = n_distinct(df$user_id)) %>%
    mutate(proportion = unique_students / total_students * 100) %>% filter(proportion >= 1) 
  level <- unique(a$game_level)
  df_level <- df %>% filter(game_level %in% level)
  return(df_level)    
    }
clusters <- c("C1", "C2", "C3", "C4", "C5", "C6", "C7", "C8", "C9")
grades <- c("G1", "G2")
games <- c("al", "cu", "st", "sb")
# Loop over each cluster, grade, and game
for (cluster in clusters) {
  for (grade in grades) {
    for (game in games) {
      # Construct the key for this combination of cluster, grade, and game
      key <- paste0(cluster, "_", grade, "_", game)
      # Check if this key exists in processed_data
      if (key %in% names(processed_data1)) {
        # If it does, apply the process_data function to the corresponding dataset
        processed_data1[[key]] <- process_data(processed_data1[[key]])
      }
    }
  }
}
# Additional code to filter game_level for the "curioso_crossing" game
for (cluster in clusters) {
  for (grade in grades) {
    # Construct the key for the "curioso_crossing" game
    key <- paste0(cluster, "_", grade, "_cu")
    # Check if this key exists in processed_data
    if (key %in% names(processed_data1)) {
      # If it does, filter game_level
      processed_data1[[key]] <- processed_data1[[key]] %>% filter(game_level <= 70)
    }
  }
} 

    # 5. Check the number of attempts, 7 for three games, 3 for one game (MC - storyboard)
    # clean those who not mastered after 7 attempts for games: al, cu, st
    # clean those who not mastered after 3 attempts for game: sb
# Define the function
filter_attempts <- function(df, max_attempts) {
  df_clean <- df %>% filter(nth_attempt <= max_attempts)
  return(df_clean)
}
# Apply the function to each dataset
clusters <- c("C1", "C2", "C3", "C4", "C5", "C6", "C7", "C8", "C9")
grades <- c("G1", "G2")
games <- c("al", "cu", "st", "sb")
processed_data_atts <- list()
for (cluster in clusters) {
  for (grade in grades) {
    for (game in games) {
      # Construct the key for this combination of cluster, grade, and game
      key <- paste0(cluster, "_", grade, "_", game)
      # Check if this key exists in processed_data
      if (key %in% names(processed_data1)) {
        # If it does, apply the filter_attempts function to the corresponding dataset
        # Use max_attempts = 7 for games "al", "cu", "st", and max_attempts = 3 for game "sb"
        max_attempts <- if (game == "sb") 3 else 7
        processed_data_atts[[key]] <- filter_attempts(processed_data1[[key]], max_attempts)
      }
    }
  }
}
    
    # 6. Check the number of levels, ignore for three games, but must have at least 3 levels for one game (ED - curioso crossing - cc)
    # Create a new list to store the filtered datasets
    # Define the function
filter_levels <- function(df) {
  user <- df %>% group_by(user_id) %>% summarise(n = n_distinct(game_level)) %>% filter(n >= 3)
  user <- unique(user$user_id)
  df_clean <- df %>% filter(user_id %in% user)
  return(df_clean)
}
    processed_data_atts_levels <- list()
games <- c("al", "cu", "st", "sb")
for (cluster in clusters) {
  for (grade in grades) {
    for (game in games) {
      # Construct the key for this combination of cluster, grade, and game
      key <- paste0(cluster, "_", grade, "_", game)
      # Check if this key exists in processed_data_atts
      if (key %in% names(processed_data_atts)) {
        # If the game is "curioso_crossing", apply the filter_levels function
        if (game == "cc") {
          processed_data_atts_levels[[key]] <- filter_levels(processed_data_atts[[key]])
        } else {
          # Otherwise, keep the dataset as it was
          processed_data_atts_levels[[key]] <- processed_data_atts[[key]]
        }
      }
    }
  }
}

    # 7. Find both grades common users
# Create a new list to store the datasets with common users
common_data <- list()

for (cluster in clusters) {
    for (grade in grades) {
        for (game in games) {
            # Construct the keys for this cluster, grade, and game
            key_G1 <- paste0(cluster, "_G1_", game)
            key_G2 <- paste0(cluster, "_G2_", game)
            # Check if these keys exist in processed_data_atts_levels
            if (key_G1 %in% names(processed_data_atts_levels) && key_G2 %in% names(processed_data_atts_levels)) {
                # If they do, find the common users
                common_students <- intersect(processed_data_atts_levels[[key_G1]]$user_id, processed_data_atts_levels[[key_G2]]$user_id)
                # Filter the datasets for these users
                common_data[[paste0(cluster, "_G1_", game, "_common")]] <- processed_data_atts_levels[[key_G1]] %>% filter(user_id %in% common_students)
                common_data[[paste0(cluster, "_G2_", game, "_common")]] <- processed_data_atts_levels[[key_G2]] %>% filter(user_id %in% common_students)
            }
        }
    }
}

############# when looking at the common users for each cluster, grade, and game, they are too many to build the model #############
   # 8. change common_users_skills for those who played both al and cu in both years
# Initialize the list to store the filtered data
#common_data_filtered <- list()
#clusters <- paste0("C", 1:9)
#games_pairs <- list(c("al", "cu"), c("st", "sb"))

# Iterate over the clusters
#for (cluster in clusters) {
  # Iterate over the pairs of games
  #for (games in games_pairs) {
    # Find the common users who played both games in both years
  #  common_G1_game1 <- common_data[[paste0(cluster, "_G1_", games[1], "_common")]]$user_id
  #  common_G1_game2 <- common_data[[paste0(cluster, "_G1_", games[2], "_common")]]$user_id
  #  common_G2_game1 <- common_data[[paste0(cluster, "_G2_", games[1], "_common")]]$user_id
  #  common_G2_game2 <- common_data[[paste0(cluster, "_G2_", games[2], "_common")]]$user_id
  #  common_users_G1 <- intersect(common_G1_game1, common_G1_game2)
 #   common_users_G2 <- intersect(common_G2_game1, common_G2_game2)
  #  common_users <- intersect(common_users_G1, common_users_G2)

    # Filter the datasets for these users
 #   for (game in games) {
 #     for (year in c("G1", "G2")) {
 #       key <- paste0(cluster, "_", year, "_", game, "_common")
 #       common_data_filtered[[key]] <- common_data[[key]] %>% filter(user_id %in% common_users)
  #    }
 #   }
 # }
#}

   # 9. change check_mastery from TRUE/FALSE to 1/0
clusters_readyfor_model_18thMay <- lapply(common_data, function(df) {
    df$check_mastery <- ifelse(df$check_mastery == TRUE, 1, 0)
    return(df)
})

# Save the data ---- use this one
#save(clusters_readyfor_model, file = "clusters_readyfor_model.RData")
#save(clusters_readyfor_model_18thMay, file = "clusters_readyfor_model_18thMay.RData")

# load("clusters_readyfor_model_18thMay.RData")
################################# This is the step to create each dataset from the list which is easy to call them out ###############
########################### when you call out the name for each data, this will be easy to do ###############
# Create variables in the global environment
list2env(clusters_readyfor_model_18thMay, envir = .GlobalEnv)

################################### check the users for each dataset /clusters/grades/games ###################################
# Define a function to count the number of unique user_id
count_user_id <- function(data) {
    length(unique(data$user_id))
}
# Apply the function to each dataset in the list
user_id_counts <- lapply(clusters_readyfor_model_18thMay, count_user_id)
# Print the counts
print(user_id_counts)

############################################ Model Application  #######################################
#### quicker way to load the data
load("clusters_readyfor_model_18thMay.RData")
## model 0: Rasch SIRT with attempt specific parameter, baseline model for attempt parameter
fit_model0 <- function(data) {
    tryCatch({
        lme4::glmer(factor(check_mastery) ~ 0 + factor(game_level)+ factor(nth_attempt) + (1|user_id), 
                                data = data, 
                                family = binomial, 
                                nAGQ = 1, 
                                control = lme4::glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)))
    }, error = function(e) { #  not exit, but report the error
        print(paste("Error in fit_model0:", e))
        return(NULL)
    })
}

## model 1: without random slope, only random intercept, same growth rate \lamda for each person
fit_model1 <- function(data) {
    tryCatch({
        lme4::glmer(factor(check_mastery) ~ 0 + factor(game_level)+ I(nth_attempt-1) + (1|user_id), 
                                data = data, 
                                family = binomial, 
                                nAGQ = 1, 
                                control = lme4::glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)))
    }, error = function(e) { #  not exit, but report the error
        print(paste("Error in fit_model1:", e))
        return(NULL)
    })
}

# model2: with the random slope, allow difference in person specific parameter (growth rate \lamda)
fit_model2 <- function(data)  {
  tryCatch({
    lme4::glmer(factor(check_mastery) ~ 0 + factor(game_level)+ I(nth_attempt-1) + (1 + I(nth_attempt-1)| user_id), 
                data = data, 
                family = binomial, 
                nAGQ = 1, 
                control = lme4::glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)))
  }, error = function(e) {
    print(paste("Error in fit_model2:", e))
    return(NULL)
  })
}

####################################### Apply models on nine clusters #######################################
# Apply this function to each element of clusters_readyfor_model_18thMay
model0_results <- lapply(clusters_readyfor_model_18thMay, fit_model0)
model1_results <- lapply(clusters_readyfor_model_18thMay, fit_model1)
model2_results <- lapply(clusters_readyfor_model_18thMay, fit_model2)

####################################### For example only look at two clusters, such as cluster 1 (C1) and cluster 2 (C2) ######################################
C1toC2 <- clusters_readyfor_model_18thMay[1:16]
model0_results_C1toC2 <- lapply(C1toC2, fit_model0)
model1_results_C1toC2 <- lapply(C1toC2, fit_model1)
model2_results_C1toC2 <- lapply(C1toC2, fit_model2)

load("model0_results_C1toC2.RData")
load("model1_results_C1toC2.RData")
load("model2_results_C1toC2.RData")
summary(model0_results_C1toC2[1:4])
summary(model1_results_C1toC2[1:4])
summary(model1_results_C1toC2[[7]])

####################################### ANOVA Analysis #######################################
# Make sure that model1_results and model2_results have the same length
if (length(model1_results) == length(model2_results)) {
    # Initialize a list to store the ANOVA results
    anova_results <- vector("list", length(model1_results))
    
    # Iterate over the lists of models
    for (i in seq_along(model1_results)) {
        # Compare the i-th pair of models
        anova_results[[i]] <- tryCatch({
            anova(model1_results[[i]], model2_results[[i]])
        }, error = function(e) {
            print(paste("Error in anova for model pair", i, ":", e))
            return(NULL)
        })
    }
} else {
    stop("model1_results and model2_results must have the same length")
}
anova(model1_results_C1toC2[[7]], model2_results_C1toC2[[7]])

